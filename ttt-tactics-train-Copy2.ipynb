{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "both",
    "cell_id": "00000-eed71e6e-88cc-4f47-80c0-7cf291a94720",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "executionInfo": {
     "elapsed": 46743,
     "status": "ok",
     "timestamp": 1602482278243,
     "user": {
      "displayName": "Undwad",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi2LR8pxvZnN5KvU-IbaWn4pEB_L6xxtMILv0Vz=s64",
      "userId": "09404197363845193389"
     },
     "user_tz": -240
    },
    "id": "7CLObsEc-FqT",
    "outputId": "57233c7d-1c25-4092-ed02-50cc76e01e00",
    "output_cleared": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ipykernel.zmqshell.ZMQInteractiveShell object at 0x7fdd2912f760>\n",
      " composition.py   ttt-tactics\t\t   ttt-tactics-test.ipynb\n",
      "'!!!.ipynb'\t  ttt-tactics.ipynb\t   ttt-tactics-train-Copy2.ipynb\n",
      " __pycache__\t  ttt-tactics-play.ipynb   ttt-tactics-train.ipynb\n",
      " ttt-3.ipynb\t  ttt_tactics.py\n",
      "INFO:tensorflow:Using local port 18538\n",
      "INFO:tensorflow:Using local port 22416\n",
      "INFO:tensorflow:Using local port 17762\n",
      "INFO:tensorflow:Using local port 17034\n",
      "INFO:tensorflow:Using local port 24085\n",
      "INFO:tensorflow:Using local port 15886\n",
      "INFO:tensorflow:Using local port 17884\n",
      "INFO:tensorflow:Using local port 16692\n",
      "INFO:tensorflow:Using local port 23486\n",
      "INFO:tensorflow:Using local port 24338\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "cuda: False\n",
      "tensorflow: 2.4.0\n",
      "python: 3.8.5 (default, Jul 28 2020, 12:59:40) \n",
      "[GCC 9.3.0]\n",
      "module:  ttt_tactics\n",
      "DIR = ./ttt-tactics\n",
      "<function savesamples at 0x7fdcbd6b5040>\n",
      "<function loadsamples at 0x7fdcbd6b5280>\n",
      "<class 'ttt_tactics.AlphaZeroModel'>\n",
      "<function AlphaZeroPolicy at 0x7fdcbd6b5790>\n",
      "MemTotal:       16393932 kB\n",
      "MemFree:         7541536 kB\n",
      "MemAvailable:   13543536 kB\n"
     ]
    }
   ],
   "source": [
    "ipython = get_ipython()\n",
    "colab   = 'google.colab' in str(ipython)\n",
    "print(ipython)\n",
    "\n",
    "if colab:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    %cd '/content/gdrive/My Drive/Colab Notebooks'\n",
    "\n",
    "!ls \"./\"\n",
    "\n",
    "def MODULE_FROM_NOTEBOOK(target, source, *keys): \n",
    "    from json import load\n",
    "    with open(source) as notebook:\n",
    "        data = load(notebook)\n",
    "        with open(target,'w') as module:\n",
    "            for cell in data['cells']:\n",
    "                lines = cell['source']\n",
    "                if type(lines) == str:\n",
    "                    lines = lines.split('\\n')\n",
    "                line0  = (lines or [''])[0].strip()\n",
    "                haskey = lambda key: line0 == f'### {key} ###'\n",
    "                if cell['cell_type'] == 'code' and any(map(haskey,keys)):\n",
    "                    code = '\\n'.join(lines)\n",
    "                    module.write(code)\n",
    "                    module.write('\\n')\n",
    "                     \n",
    "MODULE_FROM_NOTEBOOK('./ttt_tactics.py',\n",
    "                     './ttt-tactics.ipynb',\n",
    "                     'HEAD','GAME','DATA','MODEL','SEARCH')\n",
    "\n",
    "from ttt_tactics import *\n",
    "\n",
    "!cat /proc/meminfo | grep Mem\n",
    "\n",
    "ipynb = 'ttt-tactics-train'\n",
    "\n",
    "# %load_ext tensorboard\n",
    "\n",
    "# !rm -rf \"./tensorboard/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Uv3JyAE1xgty"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.MyModel'>\n",
      "Model: \"alpha-zero-model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "state (InputLayer)              [(None, 9, 9, 6)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d (DepthwiseConv (None, 3, 3, 6)      54          state[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 3, 3, 6)      24          depthwise_conv2d[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 3, 3, 6)      0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 9, 9, 6)      0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 3, 3, 1)      6           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 9, 9, 12)     0           state[0][0]                      \n",
      "                                                                 up_sampling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 3, 3, 1)      4           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 9, 9, 2)      24          concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 3, 3, 1)      0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 9, 9, 2)      8           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 9)            0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 9, 9, 2)      0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 64)           640         flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 162)          0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "value (Dense)                   (None, 1)            65          dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "policy (Dense)                  (None, 81)           13203       flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 14,028\n",
      "Trainable params: 14,010\n",
      "Non-trainable params: 18\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def ConvLayer(filters     = None, \n",
    "              kernel_size = None, \n",
    "              strides     = None, \n",
    "              padding     = None,\n",
    "              activation  = None):\n",
    "    def proc(x, add=None):\n",
    "        kwargs = dict(kernel_size = kernel_size,\n",
    "                      strides     = strides,\n",
    "                      padding     = padding,\n",
    "                      data_format = 'channels_last',\n",
    "                      use_bias    = False)\n",
    "        if filters is None: \n",
    "            y = DepthwiseConv2D(depth_multiplier=1, **kwargs)(x)\n",
    "        else: \n",
    "            y = Conv2D(filters=filters, **kwargs)(x)\n",
    "        y = BatchNormalization()(y)\n",
    "        if add is not None:\n",
    "            y = Add()([y, add])  \n",
    "        z = Activation(activation)(y)\n",
    "        return z\n",
    "    return proc\n",
    "\n",
    "def InputLayer():\n",
    "    def proc(x):\n",
    "        z = ConvLayer(filters     = None, \n",
    "                      kernel_size = 3, \n",
    "                      strides     = 3, \n",
    "                      padding     = 'same',\n",
    "                      activation  = 'relu')(x)\n",
    "        return z\n",
    "    return proc\n",
    "\n",
    "def ValueHead():\n",
    "    def proc(x):\n",
    "        y = ConvLayer(filters     = 1, \n",
    "                      kernel_size = 1, \n",
    "                      strides     = 1, \n",
    "                      padding     = 'valid',\n",
    "                      activation  = 'relu')(x)\n",
    "        y = Flatten()(y)\n",
    "        y = Dense(64, activation='relu')(y) \n",
    "        z = Dense(1, activation='tanh', name='value')(y) \n",
    "        return z\n",
    "    return proc\n",
    "\n",
    "def PolicyHead():\n",
    "    def proc(x):\n",
    "        y = ConvLayer(filters     = 2, \n",
    "                      kernel_size = 1, \n",
    "                      strides     = 1, \n",
    "                      padding     = 'valid',\n",
    "                      activation  = 'relu')(x)\n",
    "        y = Flatten()(y)\n",
    "        z = Dense(num_a, activation='softmax', name='policy')(y)\n",
    "        return z\n",
    "    return proc\n",
    "    \n",
    "def LearningRateMetric(model):\n",
    "    def metric(y_true, y_pred):\n",
    "        return model.optimizer.lr\n",
    "    metric.__name__ = 'lr'\n",
    "    return metric    \n",
    "\n",
    "from tensorflow.keras.layers import UpSampling2D, Concatenate \n",
    "\n",
    "class MyModel(Model):\n",
    "    def __init__(self, residuals=5, path=None):\n",
    "        x = Input((9,9,6,), name='state')\n",
    "        y = InputLayer()(x)\n",
    "        q = ValueHead()(y)\n",
    "        y = UpSampling2D(size=3, data_format='channels_last', interpolation='nearest')(y)\n",
    "        y = Concatenate()([x,y])\n",
    "        p = PolicyHead()(y)\n",
    "        super(MyModel, self).__init__(inputs=x, outputs=[q,p], name='alpha-zero-model')\n",
    "        self.__name__ = self.name\n",
    "        self.compile(\n",
    "            loss         = { 'value': 'mse', 'policy': 'categorical_crossentropy' }, \n",
    "            loss_weights = { 'value': 1,     'policy': 1 },\n",
    "            optimizer    = Adam(lr=0.001, clipnorm=1.0),\n",
    "            metrics      = { 'value': [LearningRateMetric(self)] }) \n",
    "        if path is not None:\n",
    "            self.load(path)  \n",
    "    def clone():\n",
    "        clone = MyModel(residuals=residuals)\n",
    "        clone.set_weights(self.get_weights())\n",
    "        return clone\n",
    "    def softmax(self,pp,aa):\n",
    "          return pp\n",
    "    def __call__(self, s, training=False, policy=True):\n",
    "        if training:\n",
    "            q,ppp = super(MyModel, self).__call__(s, training=True)  \n",
    "            return q,ppp\n",
    "        aa    = actions(s)\n",
    "        xx    = stack([onehot(s)])\n",
    "        q,ppp = super(MyModel, self).__call__(xx, training=False)\n",
    "        q,ppp = squeeze(q),squeeze(ppp)\n",
    "        ii    = unravel(aa)\n",
    "        pp    = gather_nd(ppp,ii)\n",
    "        pp    = softmax(reshape(pp,[1,-1]))\n",
    "        pp    = reshape(pp,[-1])\n",
    "        if policy:            \n",
    "            return aa,pp\n",
    "        ppp   = zeros(num_a,pp.dtype)\n",
    "        ppp   = update_nd(ppp,ii,pp)\n",
    "        return q,ppp\n",
    "    def __str__(self):\n",
    "        return self.__name__\n",
    "    def save(self, path):\n",
    "        if isfile(path):\n",
    "            MTIME(path)\n",
    "            os.rename(path, path+'.bak')       \n",
    "            MTIME(path+'.bak')\n",
    "        self.save_weights(path, overwrite=True, save_format='h5')\n",
    "        MTIME(path)\n",
    "        self.__name__ = Path(path).stem\n",
    "    def load(self, path):\n",
    "        self.load_weights(path)\n",
    "        MTIME(path)\n",
    "        self.__name__ = Path(path).stem\n",
    "\n",
    "print(MyModel)    \n",
    "\n",
    "model = MyModel()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "plot_model(model, show_shapes=False, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./ttt-tactics/model-00000000.h5 Nov 06 2020 10:00:00\n",
      "./ttt-tactics/model-00000000.h5.bak Nov 06 2020 10:00:00\n",
      "./ttt-tactics/model-00000000.h5 Nov 06 2020 10:02:00\n"
     ]
    }
   ],
   "source": [
    "model.save(f'{DIR}/model-00000000.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "id": "SUoIZqK3oQlQ",
    "outputId": "6cfb75ff-7a57-4fba-d207-2bf96e846d59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./ttt-tactics/model-00000000.h5 Nov 06 2020 10:02:00\n",
      "WARNING:tensorflow:From /home/undwad/venv/lib/python3.8/site-packages/tensorflow/python/ops/linalg/linear_operator_full_matrix.py:150: calling LinearOperator.__init__ (from tensorflow.python.ops.linalg.linear_operator) with graph_parents is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Do not pass `graph_parents`.  They will  no longer be used.\n",
      "WARNING:tensorflow:From /home/undwad/venv/lib/python3.8/site-packages/tensorflow/python/ops/linalg/linear_operator_kronecker.py:224: LinearOperator.graph_parents (from tensorflow.python.ops.linalg.linear_operator) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Do not call `graph_parents`.\n",
      "path = ./ttt-tactics/data-*.tfrec\n",
      "files: 100\n",
      "Epoch 1/10\n",
      "    944/Unknown - 76s 72ms/step - loss: 4.9572 - value_loss: 0.7883 - policy_loss: 4.1689 - value_lr: 1.0000e-04"
     ]
    }
   ],
   "source": [
    "minloss = 3.0\n",
    "model   = MyModel()\n",
    "models  = sortedfiles(f'{DIR}/model-*.h5')\n",
    "model.load(models[-1])\n",
    "\n",
    "left = 1000\n",
    "while left > 0:\n",
    "    left   -= 1\n",
    "    path    = f'{DIR}/data-*.tfrec'\n",
    "    files   = sortedfiles(path)\n",
    "    dataset = loadsamples(files, buffer_size=200*1024, batch_size=1024, seed=None)\n",
    "    print('path =',path)\n",
    "    print('files:',len(files))\n",
    "\n",
    "    schedule = { 0:0.0001 }\n",
    "    def onschedule(epoch, lr): \n",
    "        if epoch in schedule: return schedule[epoch]  \n",
    "        else:                 return lr\n",
    "    scheduler = LearningRateScheduler(onschedule)\n",
    "    \n",
    "    @throttle(60*60)\n",
    "    def onbatch(batch, logs):\n",
    "        NOTIFY(f'{str(model)}, batch={batch}, logs={logs}', title=ipynb, priority=-1)\n",
    "    def onepoch(epoch, logs):\n",
    "        NOTIFY(f'{str(model)}, epoch={epoch}, logs={logs}', title=ipynb, priority=0)\n",
    "    def ontrain(logs):\n",
    "        ok = 'OK' if logs['loss'] < minloss else 'NO'\n",
    "        NOTIFY(f'{str(model)}, train={ok}, logs={logs}', title=ipynb, priority=1)\n",
    "    notifier = LambdaCallback(\n",
    "        on_batch_end = onbatch,\n",
    "        on_epoch_end = onepoch,\n",
    "        on_train_end = ontrain)\n",
    "    \n",
    "    history = model.fit(\n",
    "        x                   = dataset,\n",
    "        epochs              = 10,\n",
    "        verbose             = 1,\n",
    "        callbacks           = [scheduler,notifier],\n",
    "        workers             = 10,\n",
    "        use_multiprocessing = False)\n",
    "    history = history.history\n",
    "\n",
    "    loss = history['loss'][-1]\n",
    "    if loss < minloss:\n",
    "        minloss = loss\n",
    "        model.save(nextfile(models[-1]))\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(history['loss'],        label='total loss')\n",
    "    plt.plot(history['policy_loss'], label='policy loss')\n",
    "    plt.plot(history['value_loss'],  label='value loss')\n",
    "    plt.title('training history')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.savefig(f'{DIR}/{str(model)}.png')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F3BjfAKFRvsQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "|"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ttt-tactics-train.ipynb",
   "provenance": []
  },
  "deepnote_execution_queue": [
   {
    "cellId": "00002-fcbf0a34-515f-4a2a-9f7d-27da46f1f941",
    "msgId": "bde7c841-97ff-47e6-a840-53af2c9cbaac",
    "sessionId": "d384885d-990e-4079-8d42-4649ca5be88b"
   }
  ],
  "deepnote_notebook_id": "777b0eb2-67de-4cc7-8d90-a975241af1ce",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
